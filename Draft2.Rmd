---
title: "Justin + Alden Draft 2"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
```

## Loading the Data

```{r, include = FALSE}
set.seed(230)
library(car)
library(dplyr)
library(ggplot2)
library(MASS)
library(readr)
```

```{r, include = FALSE}
#read in data
world_bank_2016 <- read_csv("Data/WB.2016.csv")

# remove NA data for measles and GNI
# wbCor <- wb[!is.na(wb$Measles),]
# wbCor <- wbCor[!is.na(wbCor$GNI),]
```

```{r, include = FALSE}
myResPlots2 <- function(model, label = "Residual Plots"){
  
  #Normal quantile plot of studentized residuals
  qqPlot(rstudent(model), pch=19, main=paste("NQ Plot of Studentized Residuals,",label))
  
  #plot of fitted vs. studentized residuals
  plot(rstudent(model) ~ model$fitted.values, pch=19, col='red', xlab="Fitted Values", ylab = "Studentized Residuals",
     main = paste("Fits vs. Studentized Residuals,", label))
  abline(h=0, lwd=3)
  abline(h=c(3,-3), lty=2, col="blue")
  abline(h=c(2,-2), lty=2, col="green")
}
```

## Correlation Analysis

TODO Should I check all variable things now? I could do that with a boxplot. Or is the way I did it with the plotting the two values and seeing the clump ok?

First, we would like to see whether global health indicators are associated with economic indicators such as GNI or percent of the population in rural areas.

We acknowledge that environment indicators such as PM2.5, ...., <fill in> may cause a degree of omitted variable bias, but we believe that ... <insert reason why only looking at health indicators.

```{r}
health_indicators <- world_bank_2016 %>%
  dplyr::select(GNI, Rural, Measles, InfMort, LifeExp) %>%
  mutate(logGNI = log10(GNI)) %>%
  na.omit()
```

First, to test whether our hypothesis that GNI and Rural are good indicators of economic development....

TODO: Fix plot labels, etc.

```{r}
ggplot(data = health_indicators, aes(x = GNI, y = Rural)) +
  geom_point() +
  ggtitle("% Rural Population vs. GNI")
```

We see that they appear to be correlated, but not in a linear relationship. It appears that most countries have GNIs between 0 and 20000, which may violate a homoscedasticity assumption when running a correlation. Thus, in an effort to get to a more linear form, we transform GNI to logGNI.

```{r}
ggplot(data = health_indicators, aes(x = logGNI, y = Rural)) +
  geom_point() +
  ggtitle("% Rural Population vs. logGNI")
```

This looks much more linear! TODO: Check the other linear assumptions.

### 1. Hypotheses

TODO: In the hypothesis, should this be GNI or logGNI?

Null Hypothesis: There is no correlation between the percentage of a country living in a rural area and the GNI of a country. That is, the correlation equals 0.

Alternative Hypothesis: There is a correlation between the percentage of a country living in a rural area and the GNI of a country. That is, the correlation does not equal 0.

$$H_0: \rho = 0$$

$$H_a: \rho \neq 0$$

### 2. Observed Statistic

```{r}
(obs_stat_corr_rural_logGNI <- cor(health_indicators$Rural, health_indicators$logGNI))
```

### 3. Create null distribution

```{r}
null_dist_corr_rural_logGNI <- rep(NA, 10000)
for (i in 1:10000){
  null_dist_corr_rural_logGNI[i] <-
    cor(sample(health_indicators$Rural), health_indicators$logGNI)
}

# plot the null distribution with a red vertical line for the statistic value
hist(null_dist_corr_rural_logGNI,
     main = "Null Distribution of Correlation between % Population Rural and logGNI",
     xlab = "Correlation",
     xlim = c(-0.8, 0.8),
     nclass = 50)

# So far off that it doesn't even matter
abline(v = obs_stat_corr_rural_logGNI, col = "red")
```

### 4. Calculate p-value

```{r}
(p_value_corr_rural_logGNI <-
   sum(abs(null_dist_corr_rural_logGNI) >= abs(obs_stat_corr_rural_logGNI)) / length(null_dist_corr_rural_logGNI))
```

### 5. Conclusion

TODO: Same here, logGNI or just GNI.

A p-value of 0 is not consistent with there being no correlation between percentage of the population living in rural areas and the GNI. Our null is that the correlation coefficient is 0, so a p-value of 0 means that assuming the null is true, there is a 0% chance that we would observe a correlation coefficient statistic as extreme as ours (-0.7127915).

Thus, we see that GNI and percentage of rural population are quite correlated with each other, and thus can proceed with analyses of either one in our search for a model that predicts economic development (we will use both).

TODO: Should we do a bootstrap confidence interval here, or should we do that somewhere else?

## Linear Model Using Health Indicators

Now we begin to build our linear model to predict `logGNI`. We begin by understanding which health indicators have the strongest prediction power for `logGNI`. We start by including all the available health indicators in the dataset: `Measles`, `InfMort`, and `LifeExp`.

```{r}
GNI_all.model <- lm(logGNI ~ Measles + InfMort + LifeExp, data = health_indicators)
summary(GNI_all.model)
```

It appears that measles and infant mortality are not significant, while LifeExp is. This might be due to a high level of multicollinearity amongst the variables. Specifically, measles likely affects infant mortality, which likely affects life expectancy. We can check this by running a few tests.

```{r}
vif(GNI_all.model)
```

One way we can see whether this is true is to see the correlation between the three predictors.

```{r}
cor(health_indicators[, c("Measles", "LifeExp", "InfMort")])
```

This shows that the correlation between `LifeExp` and `InfMort` is quite high (correlation of -0.9381031), indicating that there indeed may be a high degree of multicollinearity, where one variable can predict a lot of the variability of another.

Thus, since we have a high degree of multicollinearity supported by the variability inflated factor of > 5 for both infant mortality and life expectancy as well as the high correlation, we choose to take one of the predictors out of the model. We choose to take `InfMort` out because it is one factor that contributes to life expectancy, whereas `LifeExp` likely contains other information.

```{r}
GNI_subhealth.model <- lm(logGNI ~ LifeExp + Measles, data = health_indicators)
summary(GNI_subhealth.model)
```

In fact, the `R^2` for the model containing all three variables is lower than the `R^2` for the model containing just `LifeExp` and `Measles`.

## Stepwise (Backwards and Forwards selection model)

Now that we know that GNI is an economic indicator that is relatively correlated with Life Expectancy and Measles, we can see how the various environmental factors can predict life expectancy.

To do this, we will use both a forwards and backwards selection model, using the `MASS` package.

```{r}
# Get environmental indicators
environmental_indicators <- world_bank_2016 %>%
  dplyr::select(LifeExp, PM2.5, Diesel, EnergyUse, FossilPct, Forest14, Forest94, CO2) %>%
  na.omit()

# Fit the full model
full_environmental.model <- lm(LifeExp ~ ., data = environmental_indicators)
summary(full_environmental.model)

# Stepwise regression model
step_backwards.model <- stepAIC(full_environmental.model, direction = "backward", 
                      trace = FALSE)
summary(step_backwards.model)

# Stepwise regression model
step_forwards.model <- stepAIC(full_environmental.model, direction = "forward", 
                      trace = FALSE)
summary(step_forwards.model)
```

The backwards stepwise regression model indicates that the most significant variables are:

- `PM2.5`
- `Diesel`
- `EnergyUse`
- `FossilPct`

All coefficients are significant at the 0% level.

The forwards stepwise regression model indicates that the following variables are significant:

- `PM2.5` @ 0% level
- `Diesel` @ 0% level
- `EnergyUse` @ 5% level
- `FossilPct` @ 0% level

Thus, both of these models agree, and we achieve an `adjusted R^2` of 0.6617 from the backwards model with only those variables.

## Combining the Models

Now that we understand the health and environmental indicators that are important for predicting `logGNI`, as well as the significant correlation between `logGNI` and `Rural`, we now have selected the variables that are most able to predict `logGNI`.

Let us try to find the best model now!

```{r}
combined_indicators <- world_bank_2016 %>%
  dplyr::select(LifeExp, PM2.5, Diesel, EnergyUse, FossilPct, Measles, InfMort, Rural, GNI) %>%
  mutate(logGNI = log10(GNI)) %>%
  na.omit()

# Drop GNI
combined_indicators <- combined_indicators %>%
  dplyr::select(-GNI) %>%
  na.omit()

combined_all.model <- lm(logGNI ~ ., data = combined_indicators)
summary(combined_all.model)
```

Our baseline model with all of the indicators described above results in an `R-squared` of 91.69%!

However, as discussed in the course, we should also look for relationships that are not linear, as correlations do not have to be linear. While doing this, we should also take care to not overfit to the data we have, as our ultimate goal is to have strong predicting power.

Thus, we will conduct a model selection analysis that uses the `AIC`, `BIC`, `Adjusted R^2`, and `cross-validation` techniques to find the best predictive model!

```{r}
all_r_squared <- NULL
all_adj_r_squared <- NULL
all_aic <- NULL
all_bic <- NULL

# create a for loop to extract the relevant statistics 
for (i in 1:5) {
  current_model_fit <- lm(logGNI ~ polym(LifeExp, PM2.5, Diesel, EnergyUse, FossilPct, Measles, InfMort, Rural, degree = i), data = combined_indicators)
  current_model_summary <- summary(current_model_fit)
  all_r_squared[i] <- current_model_summary$r.squared
  all_adj_r_squared[i] <- current_model_summary$adj.r.squared
  all_aic[i] <- AIC(current_model_fit)
  all_bic[i] <- BIC(current_model_fit)
}

# print the degree selected by each model selection method using
# the which.max() or which.min() functions
which.max(all_r_squared)
which.max(all_adj_r_squared)
which.min(all_aic)
which.min(all_bic)
```

And as our last metric, we should look at the cross validation method!

```{r}
# create the training set and the test set
total_num_points <- dim(combined_indicators)[1]
num_training_points <- floor(total_num_points/2)

training_data <- combined_indicators[1:num_training_points, ]
test_data <- combined_indicators[(num_training_points + 1):total_num_points, ]

# run a for loop to calculate the MSPE for models of degree 1 to 5 
all_mspe <- NULL
# then find the model with the minimal MSPE
for (i in 1:5) {
  print(i)
  current_model_fit <- lm(logGNI ~ poly(LifeExp, PM2.5, Diesel, EnergyUse, FossilPct, Measles, InfMort, Rural, degree = i), data = combined_indicators)
  current_model_predictions <- predict(current_model_fit, newdata = test_data)
  all_mspe[i] <- mean((current_model_predictions - test_data$logGNI)^2)
}

which.min(all_mspe)
```

Thus, our table looks like:

|             |    1    |    2    |    3    |    4    |    5    |
|-------------|---------|---------|---------|---------|---------|
| $R^2$       |         |         |    x    |         |         |
| $R^2_{adj}$ |         |    x    |         |         |         |
|  AIC        |         |         |    x    |         |         |
|  BIC        |         |         |    x    |         |         |
|  cross-val  |         |         |    x    |         |         |

Thus, it seems like a polynomial model with degree 3 works the best!

However, we notice that when running the `predict` function for our cross validation, we get the following error:

`prediction from a rank-deficient fit may be misleading`

This means that we are using many many variables to predict `logGNI` and thus our model is likely overfitting.

Let's examine the `AIC` and `BIC` values...

```{r}
all_aic
all_bic
```

When we examine the `AIC` and `BIC`, we see that model is overfitting, as models with degree 3 or higher have `AIC` and `BIC` of `-Inf`.

Thus, let us compare the prediction power of the polynomial with degree 2 and degree 1.

First, let's examine the `mspe` and see which one is better.

```{r}
all_mspe
```

We see that the `mspe` for a polynomial degree 2 fit is less than that of a polynomial with degree 1. Thus, we believe that the model with the best prediction power will be the polynomial with degree 2.

```{r}
# Degree 2 was shown to be most effective
final_combined.model <- lm(logGNI ~ poly(LifeExp, PM2.5, Diesel, EnergyUse, FossilPct, Measles, InfMort, Rural, degree = 2), data = combined_indicators)
summary(final_combined.model)
```

Let us try our best to shrink this model a little bit using the backwards selection

```{r}
# Stepwise regression model
final_step_backwards.model <- stepAIC(final_combined.model, direction = "backward", 
                      trace = FALSE)
summary(final_step_backwards.model)
```

Both the `final_combined` model (terms up to degree 2) and the `final_step_backwards` model (terms up to degree 2) have an adjusted R-squared of 0.9253, so our final model is thus the `final_step_backwards` model.

Note that our model seems to be quite good at prediction but we acknowledge the following:

- We are using a large amount of variables relative to how much data we have.
- Our model is not very interpretable due to the presence of many predictors. However, we believe that as the goal of this model is to maximize prediction power, this is ok. This is why we began our analyses with the different types of indicators to make the model more interpretable, that is, first looking at significant health indicators, then at significant environmental indicators, and then combining the model.